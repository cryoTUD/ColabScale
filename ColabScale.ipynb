{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryoTUD/ColabScale/blob/development/ColabScale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJazoLi-Uy0k"
      },
      "source": [
        "<img src=\"https://gitlab.tudelft.nl/aj-lab/locscale/-/raw/master/doc/img/LocScale_logo.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "#```ColabScale```\n",
        "\n",
        "Easy to use cryo-EM map sharpening using [```LocScale```](https://gitlab.tudelft.nl/aj-lab/locscale) and generation of feature-enhanced maps with [```LocScale-EMmerNet```](https://gitlab.tudelft.nl/aj-lab/emmernet).\n",
        "\n",
        "\n",
        "For more details, see <a href=\"#Instructions\">instructions</a> at the bottom of the notebook and read our manuscripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-GTilmzk5oTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c772f3-fdda-454d-ba68-e361bf3f684f",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 27 µs, sys: 5 µs, total: 32 µs\n",
            "Wall time: 34.8 µs\n"
          ]
        }
      ],
      "source": [
        "# @title 1) Setup environment\n",
        "#@markdown #### Please make sure to connect to a GPU runtime before starting.\n",
        "#%%capture\n",
        "%%time\n",
        "import os\n",
        "if not os.path.exists(\"LOCSCALE_READY\"):\n",
        "  !pip install git+https://gitlab.tudelft.nl/aj-lab/locscale.git@development\n",
        "  !pip install stackview==0.8.0\n",
        "\n",
        "  # install monomer library\n",
        "  !mkdir /usr/local/monomer_lib\n",
        "  !git clone https://github.com/MonomerLibrary/monomers.git /usr/local/monomer_lib\n",
        "  !export CLIBD_MON=/usr/local/monomer_lib/\n",
        "\n",
        "  !touch LOCSCALE_READY\n",
        "  os.kill(os.getpid(), 9)\n",
        "\n",
        "#@markdown ##### This kernel will crash after running it once. You can safely restart it afterwards.\n",
        "#@markdown ##### Ignore any errors related to pip dependancy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### 1b) Give a name for this job\n",
        "job_name = 'my_test_hybrid' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nyfMWr16hBSk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2) Get all imports\n",
        "import os\n",
        "import sys\n",
        "import gzip\n",
        "from google.colab import files\n",
        "from locscale.include.emmer.ndimage.map_tools import add_half_maps\n",
        "from locscale.utils.file_tools import generate_filename_from_halfmap_path\n",
        "from locscale.automate.tools import get_defaults_dictionary\n",
        "import wget\n",
        "proper_file_format = lambda x: x.endswith('.mrc') or x.endswith('.map') or x.endswith('.pdb') or x.endswith('.cif') or x.endswith('.mmcif')\n",
        "\n",
        "def get_half_maps_from_user():\n",
        "  uploaded = files.upload()\n",
        "  halfmap_paths = []\n",
        "  assert len(uploaded) == 2, \"Please select only two files...\"\n",
        "  for map in uploaded.keys():\n",
        "    if proper_file_format(map):\n",
        "      halfmap_paths.append(map)\n",
        "    else:\n",
        "      print(\"Uploaded file format is not either MRC or MAP; please select correct file...\")\n",
        "      os.remove(map)\n",
        "      uploaded = files.upload()\n",
        "      os.rename(map,map)\n",
        "      halfmap_paths.append(map)\n",
        "\n",
        "  return halfmap_paths\n",
        "\n",
        "\n",
        "def get_full_map_from_user():\n",
        "  uploaded = files.upload()\n",
        "  assert len(uploaded) == 1, \"Please select only one file...\"\n",
        "  for map in uploaded.keys():\n",
        "    if proper_file_format(map):\n",
        "      return map\n",
        "    else:\n",
        "      print(\"Uploaded file format is not either MRC or MAP; please select correct file...\")\n",
        "      os.remove(map)\n",
        "      uploaded = files.upload()\n",
        "      os.rename(map,map)\n",
        "      return map\n",
        "\n",
        "def get_model_from_user():\n",
        "  uploaded = files.upload()\n",
        "  assert len(uploaded) == 1, \"Please select only one file...\"\n",
        "  for model in uploaded.keys():\n",
        "    if model.endswith('.pdb'):\n",
        "      return model\n",
        "    else:\n",
        "      print(\"Uploaded file is not a PDB file; please select correct file...\")\n",
        "      os.remove(model)\n",
        "      uploaded = files.upload()\n",
        "      os.rename(model,model)\n",
        "      return model\n",
        "\n",
        "def uncompress_if_needed(file_path):\n",
        "  \"\"\"Uncompresses the file at the given path if it is compressed.\"\"\"\n",
        "  if file_path.endswith('.gz'):\n",
        "    uncompressed_path = file_path[:-3]\n",
        "    with gzip.open(file_path, 'rb') as f_in:\n",
        "      with open(uncompressed_path, 'wb') as f_out:\n",
        "        f_out.write(f_in.read())\n",
        "    print(f\"Uncompressed {file_path} to {uncompressed_path}\")\n",
        "    return uncompressed_path\n",
        "  return file_path\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "404f2a73hOJN",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  3) What kind of inputs do I want?\n",
        "my_own_data = False #@param {type:\"boolean\"}\n",
        "example_from_emdb = True #@param {type:\"boolean\"}\n",
        "\n",
        "assert my_own_data or example_from_emdb, \"Please select at least one option...\"\n",
        "if my_own_data and example_from_emdb:\n",
        "  print(\"You've selected both 'My own data' and 'Example from EMDB'.\\nTo avoid conflicts, we'll prioritize using your own data.\\nIf you prefer to use the EMDB example, please uncheck the 'My own data' option.\")\n",
        "  example_from_emdb = False\n"
      ],
      "metadata": {
        "id": "Mdq8THAUk99M",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### 3 a) Use my own data\n",
        "#@markdown ##### Run this code cell to upload your half maps. The maps will be deleted after runtime.\n",
        "if my_own_data:\n",
        "  use_full_map_instead = True #@param {type:\"boolean\"}\n",
        "  if not use_full_map_instead:\n",
        "    halfmap_paths = []\n",
        "    half_maps = {}\n",
        "    half_maps_directory = os.path.join(job_name, f\"half_maps\")\n",
        "    os.makedirs(half_maps_directory, exist_ok=True)\n",
        "    print(\"Please select half maps...\")\n",
        "    halfmap_paths_raw = get_half_maps_from_user()\n",
        "    for map in halfmap_paths_raw:\n",
        "      new_map_path = os.path.join(half_maps_directory, map)\n",
        "      os.rename(map,new_map_path)\n",
        "      halfmap_paths.append(new_map_path)\n",
        "\n",
        "  else:\n",
        "    raw_input_map_path = get_full_map_from_user()\n",
        "    input_map_path = os.path.join(job_name, os.path.basename(raw_input_map_path))\n",
        "    os.rename(raw_input_map_path, input_map_path)\n",
        "\n",
        "  filter_my_halfmaps = False #@param {type:\"boolean\"}\n",
        "  if use_full_map_instead and filter_my_halfmaps:\n",
        "    print(\"Filtering inputs only possible with half-maps.\\nSince you have chosen to upload full map as input, the filter_my_halfmaps option will be ignored\")\n",
        "\n",
        "  apply_fsc_filter = filter_my_halfmaps if not use_full_map_instead else False\n",
        "\n",
        "  # Example usage for half maps:\n",
        "  if not use_full_map_instead:\n",
        "    input_half_map_path_1 = halfmap_paths[0]\n",
        "    input_half_map_path_2 = halfmap_paths[1]\n",
        "    input_half_map_path_1 = uncompress_if_needed(input_half_map_path_1)\n",
        "    input_half_map_path_2 = uncompress_if_needed(input_half_map_path_2)\n",
        "    emmap_path_filename = generate_filename_from_halfmap_path(input_half_map_path_1)\n",
        "    emmap_path = add_half_maps(input_half_map_path_1, input_half_map_path_2, emmap_path_filename, fsc_filter=apply_fsc_filter)\n",
        "  else:\n",
        "    input_map_path = uncompress_if_needed(input_map_path)\n",
        "    emmap_path = input_map_path"
      ],
      "metadata": {
        "cellView": "form",
        "id": "K9aO_2VAhQKC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### 3 b) Example from EMDB\n",
        "#@markdown ##### Choose EMDB ID\n",
        "emdb_id = \"3061\" #@param {type:\"string\"}\n",
        "if example_from_emdb:\n",
        "  halfmap_path_1_url = f\"https://files.wwpdb.org/pub/emdb/structures/EMD-{emdb_id}/other/\temd_{emdb_id}_half_map_1.map.gz\"\n",
        "  halfmap_path_2_url = f\"https://files.wwpdb.org/pub/emdb/structures/EMD-{emdb_id}/other/\temd_{emdb_id}_half_map_2.map.gz\"\n",
        "  half_maps_directory = os.path.join(job_name, f\"half_maps\")\n",
        "  os.makedirs(half_maps_directory, exist_ok=True)\n",
        "  # Download the half-maps\n",
        "  halfmap_path_1 = os.path.join(half_maps_directory, f\"emd_{emdb_id}_half_map_1.map.gz\")\n",
        "  halfmap_path_2 = os.path.join(half_maps_directory, f\"emd_{emdb_id}_half_map_2.map.gz\")\n",
        "  wget.download(halfmap_path_1_url, halfmap_path_1)\n",
        "  wget.download(halfmap_path_2_url, halfmap_path_2)\n",
        "  # Uncompress the half-maps\n",
        "  halfmap_path_1 = uncompress_if_needed(halfmap_path_1)\n",
        "  halfmap_path_2 = uncompress_if_needed(halfmap_path_2)\n",
        "  emmap_path_filename = generate_filename_from_halfmap_path(halfmap_path_1)\n",
        "  emmap_path = add_half_maps(halfmap_path_1, halfmap_path_2, emmap_path_filename, fsc_filter=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "ZcRXVda2pnrO",
        "outputId": "7e5b050e-bc9a-4cc7-94a8-4b956ea2d524"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uncompressed my_test_hybrid/half_maps/emd_3061_half_map_1.map.gz to my_test_hybrid/half_maps/emd_3061_half_map_1.map\n",
            "Uncompressed my_test_hybrid/half_maps/emd_3061_half_map_2.map.gz to my_test_hybrid/half_maps/emd_3061_half_map_2.map\n",
            "Saving as MRC file format with following properties: \n",
            "File name:  my_test_hybrid/half_maps/EMD_3061_unsharpened_fullmap.mrc\n",
            "Voxel size (1.4, 1.4, 1.4)\n",
            "Origin (0., 0., 0.)\n",
            "Shape (180, 180, 180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4) What kind of a job do I wish to run?\n",
        "job_type = \"hybrid\" # @param [\"model-based\", \"model-free\", \"hybrid\", \"feature_enhance\"]\n",
        "#@markdown - __model-based__: ```LocScale``` sharpening using atomic model\n",
        "#@markdown - __model-free__: ```LocScale``` sharpening without atomic model\n",
        "#@markdown - __hybrid__: ```LocScale``` sharpening with partial atomic model\n",
        "#@markdown - __feature_enhance__: Confidence-aware density modification with ```LocScale-EMmerNet```\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Kbi9kYNykSQw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5) Other file inputs\n",
        "#@markdown ##### Run this code cells to upload other files\n",
        "locscale_inputs = {}\n",
        "\n",
        "#@markdown ##### 1) Upload atomic models (Required for model based or hybrid locscale)\n",
        "use_atomic_model = True #@param {type:\"boolean\"}\n",
        "if use_atomic_model:\n",
        "   raw_model_input_path = get_model_from_user()\n",
        "   input_model_path = os.path.join(job_name, raw_model_input_path)\n",
        "   os.rename(raw_model_input_path, input_model_path)\n",
        "else:\n",
        "   input_model_path = None\n",
        "\n",
        "#@markdown ##### 2) Upload your own mask\n",
        "\n",
        "use_mask = False #@param {type:\"boolean\"}\n",
        "if use_mask:\n",
        "   raw_mask_input = get_full_map_from_user()\n",
        "   input_mask_path = os.path.join(job_name, os.path.basename(raw_mask_input))\n",
        "   os.rename(raw_mask_input, input_mask_path)\n",
        "else:\n",
        "   input_mask_path = None\n",
        "\n",
        "default_dictionary_query = \"feature_enhance\" if job_type == \"feature_enhance\" else \"locscale\"\n",
        "locscale_inputs = get_defaults_dictionary(default_dictionary_query)\n",
        "\n",
        "locscale_inputs[\"emmap_path\"] = emmap_path\n",
        "locscale_inputs[\"mask\"] = input_mask_path\n",
        "locscale_inputs[\"model_coordinates\"] = input_model_path\n",
        "locscale_inputs[\"complete_model\"] = True if job_type == \"hybrid\" else False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "l9_0x9XxfCHG",
        "outputId": "98f5afee-b18b-467d-c019-5f527fe92b93",
        "cellView": "form"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2a45d3e9-5352-48a1-b088-cd40d2388272\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2a45d3e9-5352-48a1-b088-cd40d2388272\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 5a63.pdb to 5a63.pdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5 a) Relevant options\n",
        "\n",
        "#model_resolution = None #@param {type:\"string\"}\n",
        "symmetry = \"C1\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Specifies point group for map symmetrisation. Supported groups are C<sub>n</sub>, D<sub>n</sub>, T, O, I\n",
        "#@markdown - Helical symmetry is not yet supported\n",
        "\n",
        "output_name = \"hybrid.mrc\" #@param {type:\"string\"}\n",
        "#@markdown - Base string for output file names\n",
        "#@markdown - `None` will use __`job_name`__\n",
        "locscale_inputs[\"outfile\"] = output_name\n",
        "locscale_inputs[\"symmetry\"] = symmetry\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GxbmNnNIsr5o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "hkvJDCNu4NUX"
      },
      "outputs": [],
      "source": [
        "#@title 6) Advanced Options\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "#@markdown Most of these options should be left at default. Please only change if necessary and if you know what you are doing.\n",
        "\n",
        "#@markdown #### FDR options\n",
        "\n",
        "fdr_threshold = 0.01 #@param {type:\"string\"}\n",
        "fdr_window_size = None #@param {type:\"string\"}\n",
        "fdr_filter = None #@param {type:\"string\"}\n",
        "averaging_filter_size = 3 #@param {type:\"string\"}\n",
        "mask_threshold = 0.99 #@param {type:\"string\"}\n",
        "\n",
        "locscale_inputs[\"fdr_threshold\"] = fdr_threshold\n",
        "locscale_inputs[\"fdr_window_size\"] = fdr_window_size\n",
        "locscale_inputs[\"fdr_filter\"] = fdr_filter\n",
        "locscale_inputs[\"averaging_filter_size\"] = averaging_filter_size\n",
        "locscale_inputs[\"mask_threshold\"] = mask_threshold\n",
        "\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown #### EMmerNet options\n",
        "low_context_model = False #@param {type:\"boolean\"}\n",
        "batch_size = \"16\" #@param {type:\"string\"}\n",
        "stride = 16 #@param {type:\"string\"}\n",
        "gpu_ids = \"0\" #@param {type:\"string\"}\n",
        "gpu_ids = [str(gpu_id) for gpu_id in gpu_ids.split(',')]\n",
        "locscale_inputs[\"use_low_context_model\"] = low_context_model\n",
        "locscale_inputs[\"batch_size\"] = int(batch_size)\n",
        "locscale_inputs[\"gpu_ids\"] = gpu_ids\n",
        "locscale_inputs[\"stride\"] = int(stride)\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown #### Reference options\n",
        "\n",
        "model_resolution = None #@param {type:\"string\"}\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown #### Processing options\n",
        "num_cpus = os.cpu_count()\n",
        "number_processes = 2  #@param {type:\"string\"}\n",
        "verbose = True #@param {type:\"boolean\"}\n",
        "\n",
        "if int(number_processes) > num_cpus:\n",
        "  number_processes = num_cpus\n",
        "\n",
        "locscale_inputs[\"number_processes\"] = int(number_processes)\n",
        "locscale_inputs[\"verbose\"] = verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2mFm-9cHI4wc",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c34e39-47ff-4d29-fe85-5b4a148e2144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "================================================================================\n",
            " _                 _____           _      \n",
            "| |               / ____|         | |     \n",
            "| |     ___   ___| (___   ___ __ _| | ___ \n",
            "| |    / _ \\ / __|\\___ \\ / __/ _` | |/ _ \\\n",
            "| |___| (_) | (__ ____) | (_| (_| | |  __/\n",
            "|______\\___/ \\___|_____/ \\___\\__,_|_|\\___|\n",
            "                                          \n",
            "                                          \n",
            "\n",
            "\t\t\t\t\t\tVersion: v2.3\n",
            "................................................................................\n",
            "User: None  |  Date: 30-04-2025  |  Time: 12:26:14\n",
            "\n",
            "\n",
            "Authors:\n",
            "\n",
            "\tArjen J. Jakobi (TU Delft) \n",
            "\n",
            "\tAlok Bharadwaj (TU Delft) \n",
            "\n",
            "Contributors:\n",
            "\n",
            "\tCarsten Sachse (EMBL) \n",
            "\n",
            "References:\n",
            "\n",
            "Arjen J Jakobi, Matthias Wilmanns, Carsten Sachse (2017), 'Model-based local\n",
            "\tdensity sharpening of cryo-EM maps', 'eLife 6:e27131'\n",
            "Alok Bharadwaj, Arjen J Jakobi (2022), 'Electron scattering properties of\n",
            "\tbiological macromolecules and their use for cryo-EM map sharpening', 'Faraday\n",
            "\tDiscussions D2FD00078D'\n",
            "\n",
            "\n",
            "================================================================================\n",
            "================================================================================\n",
            "Running LocScale with modality: partial_model_input_build_and_refine\n",
            "................................................................................\n",
            "Input Arguments\n",
            "................................................................................\n",
            "\temmap_path:  my_test_hybrid/half_maps/EMD_3061_unsharpened_fullmap.mrc\n",
            "\thalfmap_paths:  None\n",
            "\tfilter_input:  False\n",
            "\tmask:  None\n",
            "\tverbose:  True\n",
            "\tprint_report:  False\n",
            "\treport_filename:  locscale_report\n",
            "\toutput_processing_files:  None\n",
            "\tfdr_threshold:  0.01\n",
            "\tfdr_window_size:  None\n",
            "\taveraging_filter_size:  3\n",
            "\tfdr_filter:  None\n",
            "\tmask_threshold:  0.99\n",
            "\tmodel_path:  None\n",
            "\tuse_low_context_model:  False\n",
            "\tbatch_size:  16\n",
            "\tgpu_ids:  ['0']\n",
            "\tcube_size:  32\n",
            "\tstride:  16\n",
            "\tapply_fsc_filter:  False\n",
            "\toutfile:  hybrid.mrc\n",
            "\tmodel_map:  None\n",
            "\tmodel_coordinates:  my_test_hybrid/5a63.pdb\n",
            "\tmodel_resolution:  None\n",
            "\tsymmetry:  C1\n",
            "\twindow_size:  None\n",
            "\tmpi:  False\n",
            "\tnumber_processes:  2\n",
            "\trefmac_iterations:  10\n",
            "\tref_resolution:  None\n",
            "\tapix:  None\n",
            "\tadd_blur:  20\n",
            "\trefmac5_path:  None\n",
            "\tcref_pickle:  None\n",
            "\tcif_info:  None\n",
            "\tcomplete_model:  True\n",
            "\taveraging_window:  3\n",
            "\tbuild_using_pseudomodel:  False\n",
            "\tpseudomodel_method:  gradient\n",
            "\ttotal_iterations:  50\n",
            "\tdistance:  1.2\n",
            "\tmolecular_weight:  None\n",
            "\tactivate_pseudomodel:  False\n",
            "\tsmooth_factor:  0.3\n",
            "\tboost_secondary_structure:  1.5\n",
            "\tno_reference:  False\n",
            "\tset_local_bfactor:  20\n",
            "\tdev_mode:  False\n",
            "\tskip_refine:  False\n",
            "\tcommand:  None\n",
            "\tmodality:  partial_model_input_build_and_refine\n",
            "\tuse_theoretical_profile:  True\n",
            "\trun_type:  locscale\n",
            "................................................................................\n",
            "Copying files to /content/my_test_hybrid/half_maps/processing_files\n",
            "\n",
            "................................................................................\n",
            "Preparing your inputs for LocScale\n",
            "All dependencies are satisfied. \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/locscale/utils/file_tools.py:172: UserWarning: File /content/my_test_hybrid/half_maps/processing_files/EMD_3061_unsharpened_fullmap.mrc already exists\n",
            "  warnings.warn(f\"File {destination} already exists\")\n",
            "/usr/local/lib/python3.11/dist-packages/locscale/utils/file_tools.py:172: UserWarning: File /content/my_test_hybrid/half_maps/processing_files/5a63.pdb already exists\n",
            "  warnings.warn(f\"File {destination} already exists\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading inputs... |\n",
            "Done!\n",
            "................................................................................\n",
            "Preparing mask \n",
            "\n",
            "\t\tA mask path has not been provided. False Discovery Rate control (FDR) based confidence map will be calculated at 1% FDR \n",
            "\n",
            "Calculating FDR confidence map... -"
          ]
        }
      ],
      "source": [
        "#@title 7) Run LocScale\n",
        "from locscale.utils.startup_utils import launch_locscale_no_mpi, launch_feature_enhance_no_mpi\n",
        "\n",
        "import argparse\n",
        "args = argparse.Namespace()\n",
        "args.__dict__.update(locscale_inputs)\n",
        "\n",
        "if job_type == \"feature_enhance\":\n",
        "  launch_feature_enhance_no_mpi(args)\n",
        "else:\n",
        "  launch_locscale_no_mpi(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NQYqsB7VGI-F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "36f18654-7e33-43be-8887-611f104d197c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'my_test/half_maps/feature_enhance.mrc'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-209adf3f00e1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memmap_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0moutput_map_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memmap_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mscaled_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_map_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# set scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/include/emmer/ndimage/map_utils.py\u001b[0m in \u001b[0;36mload_map\u001b[0;34m(map_path, return_apix, verbose)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mmrcfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mlocscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maverage_voxel_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0memmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrcfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mapix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_voxel_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmrcfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoxel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mrcfile/load_functions.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(name, mode, permissive, header_only)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'BZ'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mNewMrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBzip2MrcFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     return NewMrc(name, mode=mode, permissive=permissive,\n\u001b[0m\u001b[1;32m    146\u001b[0m                   header_only=header_only)\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mrcfile/mrcfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, overwrite, permissive, header_only, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mrcfile/mrcfile.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;34m\"\"\"Open a file object to use as the I/O stream.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iostream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_test/half_maps/feature_enhance.mrc'"
          ]
        }
      ],
      "source": [
        "#@title 8) Analyse results\n",
        "#@markdown ### Display scaled and unscaled maps\n",
        "\n",
        "#!pip install stackview==0.8.0\n",
        "import stackview\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "from ipywidgets import HBox, VBox\n",
        "from locscale.include.emmer.ndimage.map_utils import load_map\n",
        "#import pyclesperanto_prototype as cle\n",
        "\n",
        "#cle.select_device(\"cupy\")\n",
        "\n",
        "\n",
        "export = True #@param {type:\"boolean\"}\n",
        "#@markdown - export output as PNG images\n",
        "input_colormap = \"gray\" #@param ['gray','plasma', 'viridis', 'inferno']\n",
        "locscale_colormap = \"inferno\" #@param ['gray','plasma', 'viridis', 'inferno']\n",
        "#@markdown - `gray`: greyscale\n",
        "#@markdown - Other options are [perceptually uniform sequential color maps](https://matplotlib.org/stable/users/explain/colors/colormaps.html#sequential)\n",
        "zoom_factor = 1 # @param {type:\"number\"}\n",
        "display_style = \"toggle\" #@param {type:\"string\"}['curtain','stacked', 'toggle']\n",
        "\n",
        "# load data\n",
        "input_map, apix = load_map(emmap_path)\n",
        "output_map_path = os.path.join(os.path.dirname(emmap_path), args.outfile)\n",
        "scaled_map = load_map(output_map_path)[0]\n",
        "\n",
        "# set scale\n",
        "input_map = input_map/input_map.max()*255\n",
        "scaled_map = scaled_map/scaled_map.max()*255\n",
        "\n",
        "# set style & arrange widgets\n",
        "if display_style == \"curtain\":\n",
        "  print(\"Input map (left) vs. LocScale map (right)\\n\")\n",
        "  w1 = stackview.curtain(input_map,scaled_map, zoom_factor=zoom_factor, axis=0, colormap=input_colormap, curtain_colormap=locscale_colormap)\n",
        "  w2 = stackview.curtain(input_map,scaled_map, zoom_factor=zoom_factor, axis=1, colormap=input_colormap, curtain_colormap=locscale_colormap)\n",
        "  w3 = stackview.curtain(input_map,scaled_map, zoom_factor=zoom_factor, axis=2, colormap=input_colormap, curtain_colormap=locscale_colormap)\n",
        "  plot_map = HBox([w1, w2, w3])\n",
        "elif display_style == \"stacked\":\n",
        "  print(\"Input map (top) vs. LocScale map (bottom)\\n\")\n",
        "  w1 = stackview.orthogonal(input_map,zoom_factor=zoom_factor, colormap=input_colormap)\n",
        "  w2 = stackview.orthogonal(scaled_map,zoom_factor=zoom_factor, colormap=locscale_colormap)\n",
        "  plot_map = VBox([w1, w2])\n",
        "elif display_style == \"toggle\":\n",
        "   print(\"Use buttons to toggle between maps\")\n",
        "   plot_map = stackview.switch(\n",
        "     {\"Input\":    input_map,\n",
        "     \"LocScale\": scaled_map,\n",
        "     },\n",
        "     colormap=[input_colormap, locscale_colormap],\n",
        "     toggleable=True)\n",
        "plot_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFH6ullX7DyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449384e0-8c12-4aa9-ec63-564f72f4872e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Uploaded my_test.zip to Google Drive with ID None\n"
          ]
        }
      ],
      "source": [
        "#@title Package and download results\n",
        "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\".\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# compress\n",
        "#shutil.make_archive(job_name, 'zip', job_name)\n",
        "\n",
        "#files.download(f\"{job_name}.zip\")\n",
        "save_to_google_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "if save_to_google_drive == True and drive:\n",
        "\n",
        "  drive.mount('/content/drive')\n",
        "  !cp -r {job_name} '/content/drive/MyDrive'\n",
        "  print(f\"Uploaded {job_name}.zip to Google Drive with ID {uploaded.get('id')}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}