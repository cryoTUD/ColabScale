{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryoTUD/ColabScale/blob/development/ColabScale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJazoLi-Uy0k"
      },
      "source": [
        "<img src=\"https://gitlab.tudelft.nl/aj-lab/locscale/-/raw/master/doc/img/LocScale_logo.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "#ColabScale\n",
        "\n",
        "Easy to use cryo-EM map optmisation using [`LocScale-2.0`](https://gitlab.tudelft.nl/aj-lab/locscale) including generation of confidence-weighted, feature-enhanced maps with [```LocScale-EMmerNet```](https://gitlab.tudelft.nl/aj-lab/emmernet).\n",
        "\n",
        "\n",
        "See the `Locscale-2.0` <a href=\"https://cryotud.github.io/locscale/a\">documentation</a> for more details, tutorials & troubleshooting, and/or read our <a href=\"#https://cryotud.github.io/locscale/about/#references\">papers</a>.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GTilmzk5oTv",
        "collapsed": true,
        "outputId": "467407c6-4b32-4cce-f85d-96f9af22c9c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/4 - ðŸ”¬ Installing LocScale 2.0... -"
          ]
        }
      ],
      "source": [
        "# @title 1) Setup environment\n",
        "#@markdown #### Please make sure to connect to a GPU runtime before starting.\n",
        "#%%capture\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "from datetime import datetime\n",
        "class HideStdout:\n",
        "    def __init__(self, wait_message=\"Please wait\", filepath=None):\n",
        "        self._stdout = sys.stdout\n",
        "        self.symbols = ['/', '-', '\\\\', '|']\n",
        "        self.index = 0\n",
        "        self.wait_message = wait_message\n",
        "        self.old_stdout = None\n",
        "        self.done_symbols = ['âœ…', 'ðŸŽ‰', 'ðŸ™Œ', 'ðŸš€']\n",
        "        self.filepath = filepath\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.old_stdout = sys.stdout\n",
        "        self.old_stdout.flush()\n",
        "        if self.filepath:\n",
        "            self.file = open(self.filepath, 'a')\n",
        "            sys.stdout = self\n",
        "        else:\n",
        "            sys.stdout = self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout = self.old_stdout\n",
        "        sys.stdout.write('\\n')\n",
        "        sys.stdout.flush()\n",
        "        choose_done_symbol = random.choice(self.done_symbols)\n",
        "        sys.stdout.write(choose_done_symbol + ' Done!\\n')\n",
        "        sys.stdout.flush()\n",
        "        if self.filepath:\n",
        "          self.file.close()\n",
        "\n",
        "        if exc_type is not None:\n",
        "            return False\n",
        "\n",
        "    def write(self, content):\n",
        "        self.old_stdout.write(f'\\r{self.wait_message}... {self.symbols[self.index % len(self.symbols)]}')\n",
        "        self.old_stdout.flush()\n",
        "        self.index += 1\n",
        "        if self.filepath:\n",
        "          self.file.write(content)\n",
        "          self.file.flush()\n",
        "\n",
        "    def flush(self):\n",
        "        if self.filepath:\n",
        "          self.file.flush()\n",
        "        pass\n",
        "\n",
        "colabscale_output = \"colabscale_output.txt\"\n",
        "\n",
        "time_installation_begin = datetime.now()\n",
        "installation_start_time_string = time_installation_begin.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "# Write a header to the output file\n",
        "output_file = open(colabscale_output, 'a')\n",
        "output_file.write(\"Welcome to ColabScale!\\n\")\n",
        "output_file.write(\"Start installation at time {}\".format(installation_start_time_string))\n",
        "output_file.write(\"-\"*50)\n",
        "output_file.close()\n",
        "\n",
        "import os\n",
        "if not os.path.exists(\"LOCSCALE_READY\"):\n",
        "  with HideStdout(\"1/4 - ðŸ”¬ Installing LocScale 2.0\", colabscale_output):\n",
        "    !pip install git+https://github.com/cryoTUD/locscale.git@development\n",
        "    !pip install stackview==0.8.0\n",
        "    !pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
        "  with HideStdout(\"2/4 - ðŸŒ Downloading models\", colabscale_output):\n",
        "    !locscale feature_enhance --download\n",
        "  with HideStdout(\"3/4 - ðŸ„ Installing LocScale-SURFER\", colabscale_output):\n",
        "    !git clone https://github.com/cryoTUD/locscale-surfer.git\n",
        "  with HideStdout(\"4/4 - ðŸ’¾ Downloading monomer library\", colabscale_output):\n",
        "    # install monomer library\n",
        "    !mkdir /usr/local/monomer_lib\n",
        "    !git clone https://github.com/MonomerLibrary/monomers.git /usr/local/monomer_lib\n",
        "    !export CLIBD_MON=/usr/local/monomer_lib/\n",
        "\n",
        "  !touch LOCSCALE_READY\n",
        "  output_file = open(colabscale_output, 'a')\n",
        "  time_installation_end = datetime.now()\n",
        "  installation_end_time_string = time_installation_end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "  output_file.write(\"Installation completed at time {}\".format(installation_end_time_string))\n",
        "  output_file.write(\"Installation took {} minutes\".format((time_installation_end - time_installation_begin).seconds/60))\n",
        "  output_file.write(\"-\"*50)\n",
        "  output_file.close()\n",
        "  os._exit(00)\n",
        "else:\n",
        "  print(\"You can now begin ColabScale!\")\n",
        "!export CLIBD_MON=/usr/local/monomer_lib/\n",
        "os.environ[\"CLIBD_MON\"] = \"/usr/local/monomer_lib\"\n",
        "#@markdown ##### This kernel will automatically restart once it has finished running.\n",
        "#@markdown __Re-run this cell to begin ColabScale.__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2) Get all imports\n",
        "import os\n",
        "import sys\n",
        "import gzip\n",
        "from google.colab import files\n",
        "from locscale.include.emmer.ndimage.map_tools import add_half_maps\n",
        "from locscale.utils.file_tools import generate_filename_from_halfmap_path\n",
        "from locscale.automate.tools import get_defaults_dictionary\n",
        "import wget\n",
        "proper_file_format = lambda x: x.endswith('.mrc') or x.endswith('.map') or x.endswith('.pdb') or x.endswith('.cif') or x.endswith('.mmcif')\n",
        "from datetime import datetime\n",
        "import threading\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import functools\n",
        "\n",
        "# import segmentation models\n",
        "!mv locscale-surfer locscalesurfer\n",
        "!rm -rf locscalesurfer/src/__init__.py\n",
        "from locscalesurfer.src.surfer import predict\n",
        "model_state_path=\"locscalesurfer/src/data/SURFER_SCUNet.pt\"\n",
        "\n",
        "class SimplifyOutput:\n",
        "    # This class was written with the help of chatGPT, model: GPT4\n",
        "    def __init__(self, filepath=None):\n",
        "      self._stdout = sys.stdout\n",
        "      self.show_progress = True\n",
        "      self.symbols = ['/', '-', '\\\\', '|']\n",
        "      self.index = 0\n",
        "      self.wait_message = \"Starting LocScale\"\n",
        "      self.old_stdout = None\n",
        "      self.locscale_started = False\n",
        "      self.stop_event = threading.Event()\n",
        "      self.filepath = filepath\n",
        "    def __enter__(self):\n",
        "      self.old_stdout = sys.stdout\n",
        "      self.old_stdout.flush()\n",
        "      self.start_time = datetime.now()\n",
        "      self.cursor_thread = threading.Thread(target=self.rotate_cursor)\n",
        "      self.cursor_thread.start()\n",
        "      if self.filepath:\n",
        "        self.file = open(self.filepath, 'a')\n",
        "        sys.stdout = self\n",
        "      else:\n",
        "        sys.stdout = self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "      if self.filepath:\n",
        "        self.file.close()\n",
        "\n",
        "      self.stop_event.set()           # Signal the thread to stop\n",
        "      self.cursor_thread.join()       # Wait for it to finish\n",
        "\n",
        "      sys.stdout = self.old_stdout\n",
        "      if self.show_progress:\n",
        "          sys.stdout.write('\\n')\n",
        "          sys.stdout.flush()\n",
        "          sys.stdout.write('Done!\\n')\n",
        "          sys.stdout.flush()\n",
        "      if exc_type is not None:\n",
        "          return False\n",
        "\n",
        "    def rotate_cursor(self):\n",
        "      while not self.stop_event.is_set():\n",
        "        self.old_stdout.write(f'\\r{self.wait_message}... {self.symbols[self.index % len(self.symbols)]}')\n",
        "        self.old_stdout.flush()\n",
        "        self.index += 1\n",
        "        self.stop_event.wait(1)  # Wait for 1 second\n",
        "\n",
        "    def write(self, content):\n",
        "      lines_to_check_and_status = {\n",
        "        \"Preparing mask\" : \"ðŸ˜· Preparing a mask\",\n",
        "        \"Building Pseudo-atomic model\" : \"âš™ï¸ Creating hybrid models (this may take a while)\",\n",
        "        \"Running model refinement\" : \"âš›ï¸ Refining Atomic Displacement Parameters (this may take a while)\",\n",
        "        \"Simulating model-map using refined\": \"ðŸ—ºï¸ Obtaining reference maps\",\n",
        "        \"Loading input\" : \"ðŸ› ï¸ Preparing inputs\",\n",
        "        \"Preparation completed. Now running LocScale\": \"ðŸ’» Running LocScale (this may take a while)\"\n",
        "      }\n",
        "\n",
        "      lines_to_check = list(lines_to_check_and_status.keys())\n",
        "      for line_to_check in lines_to_check:\n",
        "        if line_to_check in content:\n",
        "          self.wait_message = lines_to_check_and_status[line_to_check]\n",
        "\n",
        "      if \"Running MC-EMmerNet\" in content or \"Running EMmerNet\" in content:\n",
        "        self.wait_message = content.strip()\n",
        "\n",
        "      if self.filepath:\n",
        "        self.file.write(content)\n",
        "        self.file.flush()\n",
        "\n",
        "\n",
        "    def flush(self):\n",
        "        pass\n",
        "\n",
        "def get_half_maps_from_user():\n",
        "  uploaded = files.upload()\n",
        "  halfmap_paths = []\n",
        "  assert len(uploaded) == 2, \"Please select only two files...\"\n",
        "  for map in uploaded.keys():\n",
        "    if proper_file_format(map):\n",
        "      halfmap_paths.append(map)\n",
        "    else:\n",
        "      print(\"Uploaded file format is not either MRC or MAP; please select correct file...\")\n",
        "      os.remove(map)\n",
        "      uploaded = files.upload()\n",
        "      os.rename(map,map)\n",
        "      halfmap_paths.append(map)\n",
        "\n",
        "  return halfmap_paths\n",
        "\n",
        "\n",
        "def get_full_map_from_user():\n",
        "  uploaded = files.upload()\n",
        "  assert len(uploaded) == 1, \"Please select only one file...\"\n",
        "  for map in uploaded.keys():\n",
        "    if proper_file_format(map):\n",
        "      return map\n",
        "    else:\n",
        "      print(\"Uploaded file format is not either MRC or MAP; please select correct file...\")\n",
        "      os.remove(map)\n",
        "      uploaded = files.upload()\n",
        "      os.rename(map,map)\n",
        "      return map\n",
        "\n",
        "def get_model_from_user():\n",
        "  uploaded = files.upload()\n",
        "  assert len(uploaded) == 1, \"Please select only one file...\"\n",
        "  for model in uploaded.keys():\n",
        "    if model.endswith('.pdb'):\n",
        "      return model\n",
        "    else:\n",
        "      print(\"Uploaded file is not a PDB file; please select correct file...\")\n",
        "      os.remove(model)\n",
        "      uploaded = files.upload()\n",
        "      os.rename(model,model)\n",
        "      return model\n",
        "\n",
        "def uncompress_if_needed(file_path):\n",
        "  \"\"\"Uncompresses the file at the given path if it is compressed.\"\"\"\n",
        "  if file_path.endswith('.gz'):\n",
        "    uncompressed_path = file_path[:-3]\n",
        "    with gzip.open(file_path, 'rb') as f_in:\n",
        "      with open(uncompressed_path, 'wb') as f_out:\n",
        "        f_out.write(f_in.read())\n",
        "    print(f\"Uncompressed {file_path} to {uncompressed_path}\")\n",
        "    return uncompressed_path\n",
        "  return file_path\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "404f2a73hOJN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 3) Prepare ColabScale job\n",
        "job_name = 'test' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nyfMWr16hBSk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ####  3a) Define data input type\n",
        "my_own_data = False #@param {type:\"boolean\"}\n",
        "example_from_emdb = True #@param {type:\"boolean\"}\n",
        "\n",
        "assert my_own_data or example_from_emdb, \"Please select at least one option...\"\n",
        "if my_own_data and example_from_emdb:\n",
        "  print(\"You've selected both 'My own data' and 'Example from EMDB'.\\nTo avoid conflicts, we'll prioritize using your own data.\\nIf you prefer to use the EMDB example, please uncheck the 'My own data' option.\")\n",
        "  example_from_emdb = False\n"
      ],
      "metadata": {
        "id": "Mdq8THAUk99M",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### 3b) Use own data\n",
        "#@markdown ##### Run this code cell to upload your half maps. The maps will be deleted after runtime.\n",
        "if my_own_data:\n",
        "  use_full_map_instead = False #@param {type:\"boolean\"}\n",
        "  if not use_full_map_instead:\n",
        "    halfmap_paths = []\n",
        "    half_maps = {}\n",
        "    half_maps_directory = os.path.join(job_name, f\"half_maps\")\n",
        "    os.makedirs(half_maps_directory, exist_ok=True)\n",
        "    print(\"Please select half maps...\")\n",
        "    halfmap_paths_raw = get_half_maps_from_user()\n",
        "    for map in halfmap_paths_raw:\n",
        "      new_map_path = os.path.join(half_maps_directory, map)\n",
        "      os.rename(map,new_map_path)\n",
        "      halfmap_paths.append(new_map_path)\n",
        "\n",
        "  else:\n",
        "    raw_input_map_path = get_full_map_from_user()\n",
        "    input_map_path = os.path.join(job_name, os.path.basename(raw_input_map_path))\n",
        "    os.rename(raw_input_map_path, input_map_path)\n",
        "\n",
        "  filter_my_halfmaps = False #@param {type:\"boolean\"}\n",
        "  if use_full_map_instead and filter_my_halfmaps:\n",
        "    print(\"Filtering inputs only possible with half-maps.\\nSince you have chosen to upload full map as input, the filter_my_halfmaps option will be ignored\")\n",
        "\n",
        "  apply_fsc_filter = filter_my_halfmaps if not use_full_map_instead else False\n",
        "\n",
        "  # Example usage for half maps:\n",
        "  if not use_full_map_instead:\n",
        "    input_half_map_path_1 = halfmap_paths[0]\n",
        "    input_half_map_path_2 = halfmap_paths[1]\n",
        "    input_half_map_path_1 = uncompress_if_needed(input_half_map_path_1)\n",
        "    input_half_map_path_2 = uncompress_if_needed(input_half_map_path_2)\n",
        "    emmap_path_filename = generate_filename_from_halfmap_path(input_half_map_path_1)\n",
        "    emmap_path = add_half_maps(input_half_map_path_1, input_half_map_path_2, emmap_path_filename, fsc_filter=apply_fsc_filter)\n",
        "  else:\n",
        "    input_map_path = uncompress_if_needed(input_map_path)\n",
        "    emmap_path = input_map_path"
      ],
      "metadata": {
        "id": "K9aO_2VAhQKC",
        "cellView": "form"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### 3c) Example from EMDB\n",
        "#@markdown ##### Choose EMDB ID\n",
        "emdb_id = \"3061\" #@param {type:\"string\"}\n",
        "if example_from_emdb:\n",
        "  halfmap_path_1_url = f\"https://files.wwpdb.org/pub/emdb/structures/EMD-{emdb_id}/other/\temd_{emdb_id}_half_map_1.map.gz\"\n",
        "  halfmap_path_2_url = f\"https://files.wwpdb.org/pub/emdb/structures/EMD-{emdb_id}/other/\temd_{emdb_id}_half_map_2.map.gz\"\n",
        "\n",
        "  half_maps_directory = os.path.join(job_name)\n",
        "  os.makedirs(half_maps_directory, exist_ok=True)\n",
        "  # Download the half-maps\n",
        "  halfmap_path_1 = os.path.join(half_maps_directory, f\"emd_{emdb_id}_half_map_1.map.gz\")\n",
        "  halfmap_path_2 = os.path.join(half_maps_directory, f\"emd_{emdb_id}_half_map_2.map.gz\")\n",
        "  wget.download(halfmap_path_1_url, halfmap_path_1)\n",
        "  wget.download(halfmap_path_2_url, halfmap_path_2)\n",
        "  #with HideStdout(\"Downloading half-maps\"):\n",
        "    # Uncompress the half-maps\n",
        "  halfmap_path_1 = uncompress_if_needed(halfmap_path_1)\n",
        "  halfmap_path_2 = uncompress_if_needed(halfmap_path_2)\n",
        "  emmap_path_filename = generate_filename_from_halfmap_path(halfmap_path_1)\n",
        "  emmap_path = add_half_maps(halfmap_path_1, halfmap_path_2, emmap_path_filename, fsc_filter=False)"
      ],
      "metadata": {
        "id": "ZcRXVda2pnrO",
        "outputId": "b9421ebc-cdc3-46c6-e311-30a736153bf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uncompressed test/emd_3061_half_map_1.map.gz to test/emd_3061_half_map_1.map\n",
            "Uncompressed test/emd_3061_half_map_2.map.gz to test/emd_3061_half_map_2.map\n",
            "Saving as MRC file format with following properties: \n",
            "File name:  test/EMD_3061_unsharpened_fullmap.mrc\n",
            "Voxel size (1.4, 1.4, 1.4)\n",
            "Origin (0., 0., 0.)\n",
            "Shape (180, 180, 180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from locscale.include.emmer.ndimage.map_utils import load_map\n",
        "emmap, apix = load_map(emmap_path)\n",
        "print(emmap.max())\n",
        "mask = (emmap > 0.01).astype(int)"
      ],
      "metadata": {
        "id": "zqq1xEbnpnEF",
        "outputId": "7376eb33-72ee-4b20-ef28-ef6ddb5a6671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.070779026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segmented_map = predict(emmap, apix, mask, model_state_path=\"locscalesurfer/src/data/SURFER_SCUNet.pt\")\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "HOtQ0p3bp9h4",
        "outputId": "05bbe101-32ff-4b7f-b297-9443a67db6f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of cubes: 512\n",
            "Number of cubes after filtering: 90\n",
            "Prediction done. Shape: (180, 180, 180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4) Choose job type\n",
        "job_type = \"model-free\" # @param [\"model-based\", \"model-free\", \"hybrid\", \"feature_enhance\"]\n",
        "#@markdown - __model-based__: ```LocScale``` sharpening using atomic model\n",
        "#@markdown - __model-free__: ```LocScale``` sharpening without atomic model\n",
        "#@markdown - __hybrid__: ```LocScale``` sharpening with partial atomic model\n",
        "#@markdown - __feature_enhance__: Confidence-aware density modification with ```LocScale-EMmerNet```\n",
        "\n",
        "locscale_inputs = {}\n",
        "default_dictionary_query = \"feature_enhance\" if job_type == \"feature_enhance\" else \"locscale\"\n",
        "locscale_inputs = get_defaults_dictionary(default_dictionary_query)\n",
        "\n",
        "locscale_inputs[\"emmap_path\"] = emmap_path\n",
        "locscale_inputs[\"complete_model\"] = True if job_type == \"hybrid\" else False\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Kbi9kYNykSQw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5) Other input files\n",
        "#@markdown ##### Run this code cells to upload other files.\n",
        "locscale_inputs = {}\n",
        "\n",
        "#@markdown ##### 1) Upload atomic models (Required for model based or hybrid locscale)\n",
        "use_atomic_model = False #@param {type:\"boolean\"}\n",
        "#@markdown ###### or\n",
        "use_pdb_id = \"\" #@param {type:\"string\"}\n",
        "if use_atomic_model:\n",
        "  raw_model_input_path = get_model_from_user()\n",
        "  input_model_path = os.path.join(job_name, raw_model_input_path)\n",
        "  os.rename(raw_model_input_path, input_model_path)\n",
        "elif use_pdb_id:\n",
        "  input_model_path = os.path.join(job_name, f\"{use_pdb_id}.pdb\")\n",
        "  wget.download(f\"https://files.rcsb.org/download/{use_pdb_id}.pdb\", input_model_path)\n",
        "else:\n",
        "  input_model_path = None\n",
        "\n",
        "#@markdown ##### 2) Upload your own mask (optional)\n",
        "\n",
        "use_mask = False #@param {type:\"boolean\"}\n",
        "if use_mask:\n",
        "   raw_mask_input = get_full_map_from_user()\n",
        "   input_mask_path = os.path.join(job_name, os.path.basename(raw_mask_input))\n",
        "   os.rename(raw_mask_input, input_mask_path)\n",
        "else:\n",
        "   input_mask_path = None\n",
        "\n",
        "\n",
        "locscale_inputs[\"mask\"] = input_mask_path\n",
        "locscale_inputs[\"model_coordinates\"] = input_model_path\n"
      ],
      "metadata": {
        "id": "l9_0x9XxfCHG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6) Relevant options\n",
        "\n",
        "#model_resolution = None #@param {type:\"string\"}\n",
        "symmetry = \"C1\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Specifies point group for map symmetrisation. Supported groups are C<sub>n</sub>, D<sub>n</sub>, T, O, I\n",
        "#@markdown - Helical symmetry is not yet supported\n",
        "\n",
        "output_name = \"my_optimised_map.mrc\" #@param {type:\"string\"}\n",
        "#@markdown - Base string for output file names\n",
        "#@markdown - `None` will use __`job_name`__\n",
        "locscale_inputs[\"outfile\"] = output_name\n",
        "locscale_inputs[\"symmetry\"] = symmetry\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GxbmNnNIsr5o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hkvJDCNu4NUX",
        "cellView": "form",
        "outputId": "0fa0b351-44eb-47a4-89b3-55350a5b3c55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "#@title 7) Advanced Options\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
        "\n",
        "#@markdown Most of these options should be left at default. Please only change if necessary and if you know what you are doing.\n",
        "\n",
        "#@markdown #### FDR options\n",
        "\n",
        "fdr_threshold = 0.01 #@param {type:\"string\"}\n",
        "fdr_window_size = None #@param {type:\"string\"}\n",
        "fdr_filter = None #@param {type:\"string\"}\n",
        "averaging_filter_size = 3 #@param {type:\"string\"}\n",
        "mask_threshold = 0.99 #@param {type:\"string\"}\n",
        "\n",
        "locscale_inputs[\"fdr_threshold\"] = fdr_threshold\n",
        "locscale_inputs[\"fdr_window_size\"] = fdr_window_size\n",
        "locscale_inputs[\"fdr_filter\"] = fdr_filter\n",
        "locscale_inputs[\"averaging_filter_size\"] = averaging_filter_size\n",
        "locscale_inputs[\"mask_threshold\"] = mask_threshold\n",
        "\n",
        "#@markdown #### Pseudomodel options\n",
        "pseudomodel_iterations = \"20\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown #### Refinement options\n",
        "refinement_iterations = \"10\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown #### EMmerNet options\n",
        "low_context_model = False #@param {type:\"boolean\"}\n",
        "batch_size = \"48\" #@param {type:\"string\"}\n",
        "stride = 16 #@param {type:\"string\"}\n",
        "gpu_ids = \"0\" #@param {type:\"string\"}\n",
        "gpu_ids = [str(gpu_id) for gpu_id in gpu_ids.split(',')]\n",
        "locscale_inputs[\"use_low_context_model\"] = low_context_model\n",
        "locscale_inputs[\"batch_size\"] = int(batch_size)\n",
        "locscale_inputs[\"gpu_ids\"] = gpu_ids\n",
        "locscale_inputs[\"stride\"] = int(stride)\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown #### Reference options\n",
        "\n",
        "model_resolution = None #@param {type:\"string\"}\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown #### Processing options\n",
        "num_cpus = os.cpu_count()\n",
        "number_processes = \"max_cpu\"  #@param {type:\"string\"}\n",
        "verbose = True #@param {type:\"boolean\"}\n",
        "\n",
        "if number_processes == \"max_cpu\":\n",
        "  number_processes = num_cpus\n",
        "elif int(number_processes) > num_cpus:\n",
        "  number_processes = num_cpus\n",
        "\n",
        "print(number_processes)\n",
        "\n",
        "locscale_inputs[\"number_processes\"] = int(number_processes)\n",
        "locscale_inputs[\"verbose\"] = verbose\n",
        "locscale_inputs[\"model_resolution\"] = model_resolution\n",
        "locscale_inputs[\"total_iterations\"] = int(pseudomodel_iterations)\n",
        "locscale_inputs[\"refmac_iterations\"] = int(refinement_iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "2mFm-9cHI4wc",
        "cellView": "form",
        "outputId": "8b30bbc4-c22c-4890-bb85-226ac95ff0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running EMmerNet: 2it [02:47, 83.84s/it]... -\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-67642000ae80>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlaunch_feature_enhance_no_mpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlaunch_locscale_no_mpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/utils/startup_utils.py\u001b[0m in \u001b[0;36mlaunch_locscale_no_mpi\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mcopied_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Arguments used: \\n{pretty_print_dictionary(vars(copied_args))}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mcopied_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mparsed_inputs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_mask_and_maps_for_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;31m## Run LocScale non-MPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mLocScaleVol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_window_function_including_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_inputs_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/utils/prepare_inputs.py\u001b[0m in \u001b[0;36mprepare_mask_and_maps_for_scaling\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preparing model map \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3) Preparing model map\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mparsed_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xyz_modmap\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xyz_modmap_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_modmap_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/utils/prepare_inputs.py\u001b[0m in \u001b[0;36mget_modmap_from_inputs\u001b[0;34m(parsed_inputs)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# Stage 4a: Run the get_modmap pipeline                                 #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m#############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mmodmap_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_modmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0mxyz_modmap_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_axis_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodmap_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mxyz_modmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz_modmap_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/preprocessing/pipeline.py\u001b[0m in \u001b[0;36mget_modmap\u001b[0;34m(modmap_args)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_statement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mmodmap_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logger'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_statement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mpseudomodel_modmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_model_map_from_input_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodmap_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpseudomodel_modmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/preprocessing/prediction.py\u001b[0m in \u001b[0;36mpredict_model_map_from_input_map\u001b[0;34m(parsed_inputs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0memmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memmap_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0minput_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0memmernet_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_emmernet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mmodel_map_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memmernet_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_predicted_map_mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0memmap_extension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memmap_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/emmernet/run_emmernet.py\u001b[0m in \u001b[0;36mrun_emmernet\u001b[0;34m(input_dictionary)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0minput_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3) Predicting the cubes...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0moutput_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_cubes_and_assemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0moutput_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymmetrise_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/emmernet/run_emmernet.py\u001b[0m in \u001b[0;36mpredict_cubes_and_assemble\u001b[0;34m(input_dictionary)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0minput_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0minput_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_emmernet_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memmernet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmirrored_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"monte_carlo\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"physics_based\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/emmernet/run_emmernet.py\u001b[0m in \u001b[0;36mrun_emmernet_batch\u001b[0;34m(input_dictionary, emmernet_model, mirrored_strategy)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mcubes_predicted_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcubes_predicted_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mcubes_predicted_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_emmernet_batch_no_monte_carlo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcubes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memmernet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmirrored_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_visible_devices_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mcubes_predicted_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcubes_predicted_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mcubes_predicted_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/locscale/emmernet/run_emmernet.py\u001b[0m in \u001b[0;36mrun_emmernet_batch_no_monte_carlo\u001b[0;34m(cubes, emmernet_model, batch_size, mirrored_strategy, cuda_visible_devices_string)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Running EMmerNet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;31m# Run the prediction step on all GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmirrored_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;31m# Collect results from all replicas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1679\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1680\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1681\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3271\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     return mirrored_run.call_for_each_replica(\n\u001b[0m\u001b[1;32m    701\u001b[0m         self._container_strategy(), fn, args, kwargs)\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m           python_function=wrapped_fn)\n\u001b[1;32m     83\u001b[0m       \u001b[0m_cfer_fn_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title 7) Run LocScale\n",
        "from locscale.utils.startup_utils import launch_locscale_no_mpi, launch_feature_enhance_no_mpi\n",
        "import argparse\n",
        "args = argparse.Namespace()\n",
        "args.__dict__.update(locscale_inputs)\n",
        "\n",
        "locscale_output = SimplifyOutput(filepath=colabscale_output)\n",
        "with locscale_output:\n",
        "  if job_type == \"feature_enhance\":\n",
        "    launch_feature_enhance_no_mpi(args)\n",
        "  else:\n",
        "    launch_locscale_no_mpi(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQYqsB7VGI-F",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 8) Analyse results\n",
        "#@markdown ### Display scaled and unscaled maps\n",
        "\n",
        "#!pip install stackview==0.8.0\n",
        "import stackview\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "from ipywidgets import HBox, VBox\n",
        "from locscale.include.emmer.ndimage.map_utils import load_map\n",
        "#import pyclesperanto_prototype as cle\n",
        "\n",
        "#cle.select_device(\"cupy\")\n",
        "\n",
        "\n",
        "export = True #@param {type:\"boolean\"}\n",
        "#@markdown - export output as PNG images\n",
        "input_colormap = \"gray\" #@param ['gray','plasma', 'viridis', 'inferno']\n",
        "locscale_colormap = \"inferno\" #@param ['gray','plasma', 'viridis', 'inferno']\n",
        "#@markdown - `gray`: greyscale\n",
        "#@markdown - Other options are [perceptually uniform sequential color maps](https://matplotlib.org/stable/users/explain/colors/colormaps.html#sequential)\n",
        "zoom_factor = 1 # @param {type:\"number\"}\n",
        "display_style = \"curtain\" #@param {type:\"string\"}['curtain','stacked', 'toggle']\n",
        "\n",
        "# load data\n",
        "input_map, apix = load_map(emmap_path)\n",
        "output_map_path = os.path.join(os.path.dirname(emmap_path), locscale_inputs[\"outfile\"])\n",
        "scaled_map = load_map(output_map_path)[0]\n",
        "\n",
        "# set scale\n",
        "input_map = input_map/input_map.max()*255\n",
        "scaled_map = scaled_map/scaled_map.max()*255\n",
        "\n",
        "# set style & arrange widgets\n",
        "if display_style == \"curtain\":\n",
        "  print(\"Input map (left) vs. LocScale map (right)\\n\")\n",
        "  w1 = stackview.curtain(input_map,scaled_map, zoom_factor=zoom_factor, axis=0, colormap=input_colormap, curtain_colormap=locscale_colormap)\n",
        "  w2 = stackview.curtain(input_map,scaled_map, zoom_factor=zoom_factor, axis=1, colormap=input_colormap, curtain_colormap=locscale_colormap)\n",
        "  w3 = stackview.curtain(input_map,scaled_map, zoom_factor=zoom_factor, axis=2, colormap=input_colormap, curtain_colormap=locscale_colormap)\n",
        "  plot_map = HBox([w1, w2, w3])\n",
        "elif display_style == \"stacked\":\n",
        "  print(\"Input map (top) vs. LocScale map (bottom)\\n\")\n",
        "  w1 = stackview.orthogonal(input_map,zoom_factor=zoom_factor, colormap=input_colormap)\n",
        "  w2 = stackview.orthogonal(scaled_map,zoom_factor=zoom_factor, colormap=locscale_colormap)\n",
        "  plot_map = VBox([w1, w2])\n",
        "elif display_style == \"toggle\":\n",
        "   print(\"Use buttons to toggle between maps\")\n",
        "   plot_map = stackview.switch(\n",
        "     {\"Input\":    input_map,\n",
        "     \"LocScale\": scaled_map,\n",
        "     },\n",
        "     colormap=[input_colormap, locscale_colormap],\n",
        "     toggleable=True)\n",
        "plot_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFH6ullX7DyY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Package and download results\n",
        "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\".\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# compress\n",
        "download_files = True #@param {type:\"boolean\"}\n",
        "if download_files:\n",
        "  shutil.make_archive(job_name, 'zip', job_name)\n",
        "  files.download(f\"{job_name}.zip\")\n",
        "\n",
        "save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "if save_to_google_drive == True and drive:\n",
        "  drive.mount('/content/drive')\n",
        "  !cp -r {job_name} '/content/drive/MyDrive'\n",
        "  print(f\"Uploaded {job_name}.zip to Google Drive with ID {uploaded.get('id')}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}