{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryoTUD/ColabScale/blob/development/ColabScale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJazoLi-Uy0k"
      },
      "source": [
        "<img src=\"https://gitlab.tudelft.nl/aj-lab/locscale/-/raw/master/doc/img/LocScale_logo.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "#```ColabScale```\n",
        "\n",
        "Easy to use cryo-EM map sharpening using [```LocScale```](https://gitlab.tudelft.nl/aj-lab/locscale) and generation of feature-enhanced maps with [```LocScale-EMmerNet```](https://gitlab.tudelft.nl/aj-lab/emmernet).\n",
        "\n",
        "\n",
        "For more details, see <a href=\"#Instructions\">instructions</a> at the bottom of the notebook and read our manuscripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GTilmzk5oTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0382de67-ade5-49fe-f87e-4df771733ded",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/cryoTUD/locscale.git@development\n",
            "  Cloning https://github.com/cryoTUD/locscale.git (to revision development) to /tmp/pip-req-build-5d51kqhm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cryoTUD/locscale.git /tmp/pip-req-build-5d51kqhm\n",
            "  Running command git checkout -b development --track origin/development\n",
            "  Switched to a new branch 'development'\n",
            "  Branch 'development' set up to track remote branch 'development' from 'origin'.\n",
            "  Resolved https://github.com/cryoTUD/locscale.git to commit 78e9136f8fa1c9af7799edf878e8aca73ec753ef\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<=1.26,>=1.21 (from locscale==2.3)\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<=1.15,>=1.5 (from locscale==2.3)\n",
            "  Downloading scipy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from locscale==2.3) (2.2.2)\n",
            "Collecting scikit-learn==1.6 (from locscale==2.3)\n",
            "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.11/dist-packages (from locscale==2.3) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.11 in /usr/local/lib/python3.11/dist-packages (from locscale==2.3) (0.13.2)\n",
            "Collecting biopython>=1.78 (from locscale==2.3)\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting gemmi==0.7.* (from locscale==2.3)\n",
            "  Downloading gemmi-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting mrcfile>=1.3.0 (from locscale==2.3)\n",
            "  Downloading mrcfile-1.5.4-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pypdb==2.0 (from locscale==2.3)\n",
            "  Downloading pypdb-2.0-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting tensorflow-addons>=0.19 (from locscale==2.3)\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow-datasets>=4.8 in /usr/local/lib/python3.11/dist-packages (from locscale==2.3) (4.9.8)\n",
            "Requirement already satisfied: more-itertools>=8.10.0 in /usr/local/lib/python3.11/dist-packages (from locscale==2.3) (10.7.0)\n",
            "Collecting servalcat==0.4.* (from locscale==2.3)\n",
            "  Downloading servalcat-0.4.105-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting pwlf>=2.0.4 (from locscale==2.3)\n",
            "  Downloading pwlf-2.5.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.11/dist-packages (from locscale==2.3) (4.67.1)\n",
            "Collecting pyfiglet>=0.8.post1 (from locscale==2.3)\n",
            "  Downloading pyfiglet-1.0.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting wget>=3.2 (from locscale==2.3)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting loguru (from locscale==2.3)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tensorflow==2.15.0.post1 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading tensorflow-2.15.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pypdb==2.0->locscale==2.3) (2.32.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6->locscale==2.3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6->locscale==2.3) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from servalcat==0.4.*->locscale==2.3) (24.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (3.4.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (4.13.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (1.71.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting nvidia-cublas-cu12==12.2.5.6 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_cublas_cu12-12.2.5.6-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.2.142 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.2.142-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvcc-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.4.25 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.8.103 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_cufft_cu12-11.0.8.103-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.3.141 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_curand_cu12-10.3.3.141-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.5.2.141 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.2.141 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.16.5 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_nccl_cu12-2.16.5-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->locscale==2.3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->locscale==2.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->locscale==2.3) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->locscale==2.3) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->locscale==2.3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->locscale==2.3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->locscale==2.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->locscale==2.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->locscale==2.3) (2025.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons>=0.19->locscale==2.3)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets>=4.8->locscale==2.3) (0.7.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets>=4.8->locscale==2.3) (0.1.9)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets>=4.8->locscale==2.3) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets>=4.8->locscale==2.3) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets>=4.8->locscale==2.3) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets>=4.8->locscale==2.3) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets>=4.8->locscale==2.3) (18.1.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets>=4.8->locscale==2.3) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets>=4.8->locscale==2.3) (1.17.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets>=4.8->locscale==2.3) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (0.45.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets>=4.8->locscale==2.3) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets>=4.8->locscale==2.3) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets>=4.8->locscale==2.3) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets>=4.8->locscale==2.3) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pypdb==2.0->locscale==2.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pypdb==2.0->locscale==2.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pypdb==2.0->locscale==2.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pypdb==2.0->locscale==2.3) (2025.4.26)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (3.1.3)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-datasets>=4.8->locscale==2.3) (25.3.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets>=4.8->locscale==2.3) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets>=4.8->locscale==2.3) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0.post1->tensorflow[and-cuda]==2.15.0.post1; platform_system != \"Darwin\"->locscale==2.3) (3.2.2)\n",
            "Downloading gemmi-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdb-2.0-py3-none-any.whl (23 kB)\n",
            "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading servalcat-0.4.105-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (747 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m747.1/747.1 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.2.5.6-py3-none-manylinux1_x86_64.whl (417.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.8/417.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.2.142-py3-none-manylinux1_x86_64.whl (13.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (23.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (845 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.8/845.8 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl (720.1 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m720.1/720.1 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @title 1) Setup environment\n",
        "#@markdown #### Please make sure to connect to a GPU runtime before starting.\n",
        "#%%capture\n",
        "%%time\n",
        "import os\n",
        "if not os.path.exists(\"LOCSCALE_READY\"):\n",
        "  !pip install git+https://github.com/cryoTUD/locscale.git@development\n",
        "  !pip install stackview==0.8.0\n",
        "  !locscale feature_enhance --download\n",
        "\n",
        "  # install monomer library\n",
        "  !mkdir /usr/local/monomer_lib\n",
        "  !git clone https://github.com/MonomerLibrary/monomers.git /usr/local/monomer_lib\n",
        "  !export CLIBD_MON=/usr/local/monomer_lib/\n",
        "\n",
        "  !touch LOCSCALE_READY\n",
        "  os.kill(os.getpid(), 9)\n",
        "\n",
        "!export CLIBD_MON=/usr/local/monomer_lib/\n",
        "os.environ[\"CLIBD_MON\"] = \"/usr/local/monomer_lib\"\n",
        "#@markdown ##### This kernel will crash after running it once. You can safely restart it afterwards.\n",
        "#@markdown ##### Ignore any errors related to pip dependancy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### 1b) Give a name for this job\n",
        "job_name = 'mytest' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nyfMWr16hBSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2) Get all imports\n",
        "import os\n",
        "import sys\n",
        "import gzip\n",
        "from google.colab import files\n",
        "from locscale.include.emmer.ndimage.map_tools import add_half_maps\n",
        "from locscale.utils.file_tools import generate_filename_from_halfmap_path\n",
        "from locscale.automate.tools import get_defaults_dictionary\n",
        "import wget\n",
        "proper_file_format = lambda x: x.endswith('.mrc') or x.endswith('.map') or x.endswith('.pdb') or x.endswith('.cif') or x.endswith('.mmcif')\n",
        "\n",
        "def get_half_maps_from_user():\n",
        "  uploaded = files.upload()\n",
        "  halfmap_paths = []\n",
        "  assert len(uploaded) == 2, \"Please select only two files...\"\n",
        "  for map in uploaded.keys():\n",
        "    if proper_file_format(map):\n",
        "      halfmap_paths.append(map)\n",
        "    else:\n",
        "      print(\"Uploaded file format is not either MRC or MAP; please select correct file...\")\n",
        "      os.remove(map)\n",
        "      uploaded = files.upload()\n",
        "      os.rename(map,map)\n",
        "      halfmap_paths.append(map)\n",
        "\n",
        "  return halfmap_paths\n",
        "\n",
        "\n",
        "def get_full_map_from_user():\n",
        "  uploaded = files.upload()\n",
        "  assert len(uploaded) == 1, \"Please select only one file...\"\n",
        "  for map in uploaded.keys():\n",
        "    if proper_file_format(map):\n",
        "      return map\n",
        "    else:\n",
        "      print(\"Uploaded file format is not either MRC or MAP; please select correct file...\")\n",
        "      os.remove(map)\n",
        "      uploaded = files.upload()\n",
        "      os.rename(map,map)\n",
        "      return map\n",
        "\n",
        "def get_model_from_user():\n",
        "  uploaded = files.upload()\n",
        "  assert len(uploaded) == 1, \"Please select only one file...\"\n",
        "  for model in uploaded.keys():\n",
        "    if model.endswith('.pdb'):\n",
        "      return model\n",
        "    else:\n",
        "      print(\"Uploaded file is not a PDB file; please select correct file...\")\n",
        "      os.remove(model)\n",
        "      uploaded = files.upload()\n",
        "      os.rename(model,model)\n",
        "      return model\n",
        "\n",
        "def uncompress_if_needed(file_path):\n",
        "  \"\"\"Uncompresses the file at the given path if it is compressed.\"\"\"\n",
        "  if file_path.endswith('.gz'):\n",
        "    uncompressed_path = file_path[:-3]\n",
        "    with gzip.open(file_path, 'rb') as f_in:\n",
        "      with open(uncompressed_path, 'wb') as f_out:\n",
        "        f_out.write(f_in.read())\n",
        "    print(f\"Uncompressed {file_path} to {uncompressed_path}\")\n",
        "    return uncompressed_path\n",
        "  return file_path\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "404f2a73hOJN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  3) What kind of inputs do I want?\n",
        "my_own_data = False #@param {type:\"boolean\"}\n",
        "example_from_emdb = True #@param {type:\"boolean\"}\n",
        "\n",
        "assert my_own_data or example_from_emdb, \"Please select at least one option...\"\n",
        "if my_own_data and example_from_emdb:\n",
        "  print(\"You've selected both 'My own data' and 'Example from EMDB'.\\nTo avoid conflicts, we'll prioritize using your own data.\\nIf you prefer to use the EMDB example, please uncheck the 'My own data' option.\")\n",
        "  example_from_emdb = False\n"
      ],
      "metadata": {
        "id": "Mdq8THAUk99M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### 3 a) Use my own data\n",
        "#@markdown ##### Run this code cell to upload your half maps. The maps will be deleted after runtime.\n",
        "if my_own_data:\n",
        "  use_full_map_instead = False #@param {type:\"boolean\"}\n",
        "  if not use_full_map_instead:\n",
        "    halfmap_paths = []\n",
        "    half_maps = {}\n",
        "    half_maps_directory = os.path.join(job_name, f\"half_maps\")\n",
        "    os.makedirs(half_maps_directory, exist_ok=True)\n",
        "    print(\"Please select half maps...\")\n",
        "    halfmap_paths_raw = get_half_maps_from_user()\n",
        "    for map in halfmap_paths_raw:\n",
        "      new_map_path = os.path.join(half_maps_directory, map)\n",
        "      os.rename(map,new_map_path)\n",
        "      halfmap_paths.append(new_map_path)\n",
        "\n",
        "  else:\n",
        "    raw_input_map_path = get_full_map_from_user()\n",
        "    input_map_path = os.path.join(job_name, os.path.basename(raw_input_map_path))\n",
        "    os.rename(raw_input_map_path, input_map_path)\n",
        "\n",
        "  filter_my_halfmaps = False #@param {type:\"boolean\"}\n",
        "  if use_full_map_instead and filter_my_halfmaps:\n",
        "    print(\"Filtering inputs only possible with half-maps.\\nSince you have chosen to upload full map as input, the filter_my_halfmaps option will be ignored\")\n",
        "\n",
        "  apply_fsc_filter = filter_my_halfmaps if not use_full_map_instead else False\n",
        "\n",
        "  # Example usage for half maps:\n",
        "  if not use_full_map_instead:\n",
        "    input_half_map_path_1 = halfmap_paths[0]\n",
        "    input_half_map_path_2 = halfmap_paths[1]\n",
        "    input_half_map_path_1 = uncompress_if_needed(input_half_map_path_1)\n",
        "    input_half_map_path_2 = uncompress_if_needed(input_half_map_path_2)\n",
        "    emmap_path_filename = generate_filename_from_halfmap_path(input_half_map_path_1)\n",
        "    emmap_path = add_half_maps(input_half_map_path_1, input_half_map_path_2, emmap_path_filename, fsc_filter=apply_fsc_filter)\n",
        "  else:\n",
        "    input_map_path = uncompress_if_needed(input_map_path)\n",
        "    emmap_path = input_map_path"
      ],
      "metadata": {
        "cellView": "form",
        "id": "K9aO_2VAhQKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### 3 b) Example from EMDB\n",
        "#@markdown ##### Choose EMDB ID\n",
        "emdb_id = \"3061\" #@param {type:\"string\"}\n",
        "if example_from_emdb:\n",
        "  halfmap_path_1_url = f\"https://files.wwpdb.org/pub/emdb/structures/EMD-{emdb_id}/other/\temd_{emdb_id}_half_map_1.map.gz\"\n",
        "  halfmap_path_2_url = f\"https://files.wwpdb.org/pub/emdb/structures/EMD-{emdb_id}/other/\temd_{emdb_id}_half_map_2.map.gz\"\n",
        "  half_maps_directory = os.path.join(job_name, f\"half_maps\")\n",
        "  os.makedirs(half_maps_directory, exist_ok=True)\n",
        "  # Download the half-maps\n",
        "  halfmap_path_1 = os.path.join(half_maps_directory, f\"emd_{emdb_id}_half_map_1.map.gz\")\n",
        "  halfmap_path_2 = os.path.join(half_maps_directory, f\"emd_{emdb_id}_half_map_2.map.gz\")\n",
        "  wget.download(halfmap_path_1_url, halfmap_path_1)\n",
        "  wget.download(halfmap_path_2_url, halfmap_path_2)\n",
        "  # Uncompress the half-maps\n",
        "  halfmap_path_1 = uncompress_if_needed(halfmap_path_1)\n",
        "  halfmap_path_2 = uncompress_if_needed(halfmap_path_2)\n",
        "  emmap_path_filename = generate_filename_from_halfmap_path(halfmap_path_1)\n",
        "  emmap_path = add_half_maps(halfmap_path_1, halfmap_path_2, emmap_path_filename, fsc_filter=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "ZcRXVda2pnrO",
        "outputId": "13cb764c-cd2f-40b1-d9c7-8de5aea6b741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uncompressed my_test_hybrid/half_maps/emd_3061_half_map_1.map.gz to my_test_hybrid/half_maps/emd_3061_half_map_1.map\n",
            "Uncompressed my_test_hybrid/half_maps/emd_3061_half_map_2.map.gz to my_test_hybrid/half_maps/emd_3061_half_map_2.map\n",
            "Saving as MRC file format with following properties: \n",
            "File name:  my_test_hybrid/half_maps/EMD_3061_unsharpened_fullmap.mrc\n",
            "Voxel size (1.4, 1.4, 1.4)\n",
            "Origin (0., 0., 0.)\n",
            "Shape (180, 180, 180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4) What kind of a job do I wish to run?\n",
        "job_type = \"hybrid\" # @param [\"model-based\", \"model-free\", \"hybrid\", \"feature_enhance\"]\n",
        "#@markdown - __model-based__: ```LocScale``` sharpening using atomic model\n",
        "#@markdown - __model-free__: ```LocScale``` sharpening without atomic model\n",
        "#@markdown - __hybrid__: ```LocScale``` sharpening with partial atomic model\n",
        "#@markdown - __feature_enhance__: Confidence-aware density modification with ```LocScale-EMmerNet```\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Kbi9kYNykSQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5) Other file inputs\n",
        "#@markdown ##### Run this code cells to upload other files\n",
        "locscale_inputs = {}\n",
        "\n",
        "#@markdown ##### 1) Upload atomic models (Required for model based or hybrid locscale)\n",
        "use_atomic_model = True #@param {type:\"boolean\"}\n",
        "if use_atomic_model:\n",
        "   raw_model_input_path = get_model_from_user()\n",
        "   input_model_path = os.path.join(job_name, raw_model_input_path)\n",
        "   os.rename(raw_model_input_path, input_model_path)\n",
        "else:\n",
        "   input_model_path = None\n",
        "\n",
        "#@markdown ##### 2) Upload your own mask\n",
        "\n",
        "use_mask = False #@param {type:\"boolean\"}\n",
        "if use_mask:\n",
        "   raw_mask_input = get_full_map_from_user()\n",
        "   input_mask_path = os.path.join(job_name, os.path.basename(raw_mask_input))\n",
        "   os.rename(raw_mask_input, input_mask_path)\n",
        "else:\n",
        "   input_mask_path = None\n",
        "\n",
        "default_dictionary_query = \"feature_enhance\" if job_type == \"feature_enhance\" else \"locscale\"\n",
        "locscale_inputs = get_defaults_dictionary(default_dictionary_query)\n",
        "\n",
        "locscale_inputs[\"emmap_path\"] = emmap_path\n",
        "locscale_inputs[\"mask\"] = input_mask_path\n",
        "locscale_inputs[\"model_coordinates\"] = input_model_path\n",
        "locscale_inputs[\"complete_model\"] = True if job_type == \"hybrid\" else False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "l9_0x9XxfCHG",
        "outputId": "2ee98b76-db70-43e5-fb35-042f27f311bf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-29b588a4-7e36-4087-9b3f-45a5ff3944a2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-29b588a4-7e36-4087-9b3f-45a5ff3944a2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 5a63.pdb to 5a63.pdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5 a) Relevant options\n",
        "\n",
        "#model_resolution = None #@param {type:\"string\"}\n",
        "symmetry = \"C1\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Specifies point group for map symmetrisation. Supported groups are C<sub>n</sub>, D<sub>n</sub>, T, O, I\n",
        "#@markdown - Helical symmetry is not yet supported\n",
        "\n",
        "output_name = \"hybrid.mrc\" #@param {type:\"string\"}\n",
        "#@markdown - Base string for output file names\n",
        "#@markdown - `None` will use __`job_name`__\n",
        "locscale_inputs[\"outfile\"] = output_name\n",
        "locscale_inputs[\"symmetry\"] = symmetry\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GxbmNnNIsr5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkvJDCNu4NUX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 6) Advanced Options\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "#@markdown Most of these options should be left at default. Please only change if necessary and if you know what you are doing.\n",
        "\n",
        "#@markdown #### FDR options\n",
        "\n",
        "fdr_threshold = 0.01 #@param {type:\"string\"}\n",
        "fdr_window_size = None #@param {type:\"string\"}\n",
        "fdr_filter = None #@param {type:\"string\"}\n",
        "averaging_filter_size = 3 #@param {type:\"string\"}\n",
        "mask_threshold = 0.99 #@param {type:\"string\"}\n",
        "\n",
        "locscale_inputs[\"fdr_threshold\"] = fdr_threshold\n",
        "locscale_inputs[\"fdr_window_size\"] = fdr_window_size\n",
        "locscale_inputs[\"fdr_filter\"] = fdr_filter\n",
        "locscale_inputs[\"averaging_filter_size\"] = averaging_filter_size\n",
        "locscale_inputs[\"mask_threshold\"] = mask_threshold\n",
        "\n",
        "#@markdown #### Pseudomodel options\n",
        "pseudomodel_iterations = \"1\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown #### Refinement options\n",
        "refinement_iterations = \"1\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown #### EMmerNet options\n",
        "low_context_model = False #@param {type:\"boolean\"}\n",
        "batch_size = \"16\" #@param {type:\"string\"}\n",
        "stride = 16 #@param {type:\"string\"}\n",
        "gpu_ids = \"0\" #@param {type:\"string\"}\n",
        "gpu_ids = [str(gpu_id) for gpu_id in gpu_ids.split(',')]\n",
        "locscale_inputs[\"use_low_context_model\"] = low_context_model\n",
        "locscale_inputs[\"batch_size\"] = int(batch_size)\n",
        "locscale_inputs[\"gpu_ids\"] = gpu_ids\n",
        "locscale_inputs[\"stride\"] = int(stride)\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown #### Reference options\n",
        "\n",
        "model_resolution = None #@param {type:\"string\"}\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown #### Processing options\n",
        "num_cpus = os.cpu_count()\n",
        "number_processes = 2  #@param {type:\"string\"}\n",
        "verbose = True #@param {type:\"boolean\"}\n",
        "\n",
        "if int(number_processes) > num_cpus:\n",
        "  number_processes = num_cpus\n",
        "\n",
        "locscale_inputs[\"number_processes\"] = int(number_processes)\n",
        "locscale_inputs[\"verbose\"] = verbose\n",
        "locscale_inputs[\"model_resolution\"] = model_resolution\n",
        "locscale_inputs[\"total_iterations\"] = int(pseudomodel_iterations)\n",
        "locscale_inputs[\"refmac_iterations\"] = int(refinement_iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2mFm-9cHI4wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8a3278-379d-4916-8b52-0f910b6f43a1",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "================================================================================\n",
            " _                 _____           _      \n",
            "| |               / ____|         | |     \n",
            "| |     ___   ___| (___   ___ __ _| | ___ \n",
            "| |    / _ \\ / __|\\___ \\ / __/ _` | |/ _ \\\n",
            "| |___| (_) | (__ ____) | (_| (_| | |  __/\n",
            "|______\\___/ \\___|_____/ \\___\\__,_|_|\\___|\n",
            "                                          \n",
            "                                          \n",
            "\n",
            "\t\t\t\t\t\tVersion: v2.3\n",
            "................................................................................\n",
            "User: None  |  Date: 30-04-2025  |  Time: 13:54:12\n",
            "\n",
            "\n",
            "Authors:\n",
            "\n",
            "\tArjen J. Jakobi (TU Delft) \n",
            "\n",
            "\tAlok Bharadwaj (TU Delft) \n",
            "\n",
            "Contributors:\n",
            "\n",
            "\tCarsten Sachse (EMBL) \n",
            "\n",
            "References:\n",
            "\n",
            "Arjen J Jakobi, Matthias Wilmanns, Carsten Sachse (2017), 'Model-based local\n",
            "\tdensity sharpening of cryo-EM maps', 'eLife 6:e27131'\n",
            "Alok Bharadwaj, Arjen J Jakobi (2022), 'Electron scattering properties of\n",
            "\tbiological macromolecules and their use for cryo-EM map sharpening', 'Faraday\n",
            "\tDiscussions D2FD00078D'\n",
            "\n",
            "\n",
            "================================================================================\n",
            "================================================================================\n",
            "Running LocScale with modality: partial_model_input_build_and_refine\n",
            "................................................................................\n",
            "Input Arguments\n",
            "................................................................................\n",
            "\temmap_path:  my_test_hybrid/half_maps/EMD_3061_unsharpened_fullmap.mrc\n",
            "\thalfmap_paths:  None\n",
            "\tfilter_input:  False\n",
            "\tmask:  None\n",
            "\tverbose:  True\n",
            "\tprint_report:  False\n",
            "\treport_filename:  locscale_report\n",
            "\toutput_processing_files:  None\n",
            "\tfdr_threshold:  0.01\n",
            "\tfdr_window_size:  None\n",
            "\taveraging_filter_size:  3\n",
            "\tfdr_filter:  None\n",
            "\tmask_threshold:  0.99\n",
            "\tmodel_path:  None\n",
            "\tuse_low_context_model:  False\n",
            "\tbatch_size:  16\n",
            "\tgpu_ids:  ['0']\n",
            "\tcube_size:  32\n",
            "\tstride:  16\n",
            "\tapply_fsc_filter:  False\n",
            "\toutfile:  hybrid.mrc\n",
            "\tmodel_map:  None\n",
            "\tmodel_coordinates:  my_test_hybrid/5a63.pdb\n",
            "\tmodel_resolution:  None\n",
            "\tsymmetry:  C1\n",
            "\twindow_size:  None\n",
            "\tmpi:  False\n",
            "\tnumber_processes:  2\n",
            "\trefmac_iterations:  1\n",
            "\tref_resolution:  None\n",
            "\tapix:  None\n",
            "\tadd_blur:  20\n",
            "\trefmac5_path:  None\n",
            "\tcref_pickle:  None\n",
            "\tcif_info:  None\n",
            "\tcomplete_model:  True\n",
            "\taveraging_window:  3\n",
            "\tbuild_using_pseudomodel:  False\n",
            "\tpseudomodel_method:  gradient\n",
            "\ttotal_iterations:  1\n",
            "\tdistance:  1.2\n",
            "\tmolecular_weight:  None\n",
            "\tactivate_pseudomodel:  False\n",
            "\tsmooth_factor:  0.3\n",
            "\tboost_secondary_structure:  1.5\n",
            "\tno_reference:  False\n",
            "\tset_local_bfactor:  20\n",
            "\tdev_mode:  False\n",
            "\tskip_refine:  False\n",
            "\tcommand:  None\n",
            "\tmodality:  partial_model_input_build_and_refine\n",
            "\tuse_theoretical_profile:  True\n",
            "\trun_type:  locscale\n",
            "................................................................................\n",
            "Copying files to /content/my_test_hybrid/half_maps/processing_files\n",
            "\n",
            "................................................................................\n",
            "Preparing your inputs for LocScale\n",
            "All dependencies are satisfied. \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/locscale/utils/file_tools.py:172: UserWarning: File /content/my_test_hybrid/half_maps/processing_files/EMD_3061_unsharpened_fullmap.mrc already exists\n",
            "  warnings.warn(f\"File {destination} already exists\")\n",
            "/usr/local/lib/python3.11/dist-packages/locscale/utils/file_tools.py:172: UserWarning: File /content/my_test_hybrid/half_maps/processing_files/5a63.pdb already exists\n",
            "  warnings.warn(f\"File {destination} already exists\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading inputs... |\n",
            "Done!\n",
            "................................................................................\n",
            "Preparing mask \n",
            "\n",
            "\t\tA mask path has not been provided. False Discovery Rate control (FDR) based confidence map will be calculated at 1% FDR \n",
            "\n",
            "Calculating FDR confidence map... |\n",
            "Done!\n",
            "\t\tMask generated at /content/my_test_hybrid/half_maps/processing_files/EMD_3061_unsharpened_fullmap_confidenceMap.mrc \n",
            "\n",
            "................................................................................\n",
            "Preparing model map \n",
            "\n",
            "................................................................................\n",
            "Running model-map generation pipeline \n",
            "\n",
            "Measuring input mask parameters... -\n",
            "Done!\n",
            "a) Running pseudo-atomic model generator to complete the user-provided PDB\n",
            "Adding 9284 pseudoatoms to 5a63.pdb\n",
            "Building Pseudo-atomic model: 100%|██████████| 1/1 [00:04<00:00,  4.33s/it]\n",
            "\t\t↓\n",
            "b) Running model refinement\n",
            "\tThis is a refinement of a pseudo-atomic model\n",
            "\tRunning iterative refinement of the model for 1 cycles\n",
            "\tCycle: 0\n",
            "\tChanging to directory: /content/my_test_hybrid/half_maps/processing_files\n",
            "Running command: servalcat refine_spa_norefmac --model /content/my_test_hybrid/half_maps/processing_files/5a63_integrated_pseudoatoms_uniform_biso.cif --resolution 2.9 --ncycle 1 --output_prefix 5a63_integrated_pseudoatoms_servalcat_refined --map /content/my_test_hybrid/half_maps/processing_files/EMD_3061_unsharpened_fullmap.mrc --hydrogen no --keywords refi bonly\n"
          ]
        }
      ],
      "source": [
        "#@title 7) Run LocScale\n",
        "from locscale.utils.startup_utils import launch_locscale_no_mpi, launch_feature_enhance_no_mpi\n",
        "import argparse\n",
        "args = argparse.Namespace()\n",
        "args.__dict__.update(locscale_inputs)\n",
        "\n",
        "if job_type == \"feature_enhance\":\n",
        "  launch_feature_enhance_no_mpi(args)\n",
        "else:\n",
        "  launch_locscale_no_mpi(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQYqsB7VGI-F",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 8) Analyse results\n",
        "#@markdown ### Display scaled and unscaled maps\n",
        "\n",
        "#!pip install stackview==0.8.0\n",
        "import stackview\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "from ipywidgets import HBox, VBox\n",
        "from locscale.include.emmer.ndimage.map_utils import load_map\n",
        "#import pyclesperanto_prototype as cle\n",
        "\n",
        "#cle.select_device(\"cupy\")\n",
        "\n",
        "\n",
        "export = True #@param {type:\"boolean\"}\n",
        "#@markdown - export output as PNG images\n",
        "input_colormap = \"gray\" #@param ['gray','plasma', 'viridis', 'inferno']\n",
        "locscale_colormap = \"inferno\" #@param ['gray','plasma', 'viridis', 'inferno']\n",
        "#@markdown - `gray`: greyscale\n",
        "#@markdown - Other options are [perceptually uniform sequential color maps](https://matplotlib.org/stable/users/explain/colors/colormaps.html#sequential)\n",
        "zoom_factor = 1 # @param {type:\"number\"}\n",
        "display_style = \"toggle\" #@param {type:\"string\"}['curtain','stacked', 'toggle']\n",
        "\n",
        "# load data\n",
        "input_map, apix = load_map(emmap_path)\n",
        "output_map_path = os.path.join(os.path.dirname(emmap_path), args.outfile)\n",
        "scaled_map = load_map(output_map_path)[0]\n",
        "\n",
        "# set scale\n",
        "input_map = input_map/input_map.max()*255\n",
        "scaled_map = scaled_map/scaled_map.max()*255\n",
        "\n",
        "# set style & arrange widgets\n",
        "if display_style == \"curtain\":\n",
        "  print(\"Input map (left) vs. LocScale map (right)\\n\")\n",
        "  w1 = stackview.curtain(input_map,scaled_map, zoom_factor=zoom_factor, axis=0, colormap=input_colormap, curtain_colormap=locscale_colormap)\n",
        "  w2 = stackview.curtain(input_map,scaled_map, zoom_factor=zoom_factor, axis=1, colormap=input_colormap, curtain_colormap=locscale_colormap)\n",
        "  w3 = stackview.curtain(input_map,scaled_map, zoom_factor=zoom_factor, axis=2, colormap=input_colormap, curtain_colormap=locscale_colormap)\n",
        "  plot_map = HBox([w1, w2, w3])\n",
        "elif display_style == \"stacked\":\n",
        "  print(\"Input map (top) vs. LocScale map (bottom)\\n\")\n",
        "  w1 = stackview.orthogonal(input_map,zoom_factor=zoom_factor, colormap=input_colormap)\n",
        "  w2 = stackview.orthogonal(scaled_map,zoom_factor=zoom_factor, colormap=locscale_colormap)\n",
        "  plot_map = VBox([w1, w2])\n",
        "elif display_style == \"toggle\":\n",
        "   print(\"Use buttons to toggle between maps\")\n",
        "   plot_map = stackview.switch(\n",
        "     {\"Input\":    input_map,\n",
        "     \"LocScale\": scaled_map,\n",
        "     },\n",
        "     colormap=[input_colormap, locscale_colormap],\n",
        "     toggleable=True)\n",
        "plot_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFH6ullX7DyY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Package and download results\n",
        "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\".\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# compress\n",
        "#shutil.make_archive(job_name, 'zip', job_name)\n",
        "\n",
        "#files.download(f\"{job_name}.zip\")\n",
        "save_to_google_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "if save_to_google_drive == True and drive:\n",
        "\n",
        "  drive.mount('/content/drive')\n",
        "  !cp -r {job_name} '/content/drive/MyDrive'\n",
        "  print(f\"Uploaded {job_name}.zip to Google Drive with ID {uploaded.get('id')}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}